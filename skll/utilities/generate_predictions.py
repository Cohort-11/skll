#!/usr/bin/env python
# License: BSD 3 clause
"""
Loads a trained model and outputs predictions based on input feature files.

:author: Nitin Madnani (nmadnani@ets.org)
:author: Dan Blanchard (dblanchard@ets.org)
:organization: ETS
:date: February 2013
"""

import argparse
import logging
import os

from skll.data.readers import EXT_TO_READER
from skll.learner import Learner
from skll.version import __version__


class Predictor(object):
    """
    A wrapper around a ``Learner`` instance to load models and get
    predictions for feature strings.
    """

    def __init__(self, model_path,
                 threshold=None,
                 positive_label_index=1,
                 all_labels=False,
                 logger=None):
        """
        Initialize the predictor.

        Parameters
        ----------
        model_path : str
            Path to use when loading trained model.
        threshold : float, optional
            If the model we're using is generating probabilities
            of the positive label, return 1 if it meets/exceeds
            the given threshold and 0 otherwise.
            Defaults to ``None``.
        positive_label_index : int, optional
            If the model is only being used to predict the
            probability of a particular class, this
            specifies the index of the class we're
            predicting. 1 = second class, which is default
            for binary classification.
            Defaults to 1.
        all_labels: bool, optional
            A flag indicating whether to return the probabilities for all
            labels in each row instead of just returning the probability of
            `positive_label`. Defaults to None.
        logger : logging object, optional
            A logging object. If ``None`` is passed, get logger from ``__name__``.
            Defaults to ``None``.
        """
        # self.logger = logger if logger else logging.getLogger(__name__)
        if threshold is not None and all_labels:
            raise ValueError("`threshold` and `all_labels` are mutually "
                             "exclusive. They can not both be set to True.")

        self._learner = Learner.from_file(model_path)
        self._pos_index = positive_label_index
        self.threshold = threshold
        self.all_labels = all_labels
        self.output_file_header = None

    def predict(self, data):
        """
        Generate a list of predictions for the given examples.

        Parameters
        ----------
        data : skll.FeatureSet
            The ``FeatureSet`` instance to get predictions for.

        Returns
        -------
        A list of predictions generated by the model.
        """
        # compute the predictions from the learner
        preds = self._learner.predict(data)
        preds = preds.tolist()
        labels = self._learner.label_list

        # Create file header list, and transform predictions as needed
        # depending on the specified prediction arguments.
        if self._learner.probability:
            if self.all_labels:
                self.output_file_header = ["id"] + [str(x) for x in labels]
            elif self.threshold is None:
                label = self._learner.label_list[self._pos_index]
                self.output_file_header = ["id",
                                           "Probability of '{}'".format(label)]
                preds = [pred[self._pos_index] for pred in preds]
            else:
                self.output_file_header = ["id", "prediction"]
                preds = [int(pred[self._pos_index] >= self.threshold)
                         for pred in preds]
        elif self._learner.model._estimator_type == 'regressor':
            self.output_file_header = ["id", "prediction"]
        else:
            self.output_file_header = ["id", "prediction"]
            preds = [labels[pred if isinstance(pred, int) else int(pred[0])]
                     for pred in preds]
        return preds





def main(argv=None):
    """
    Handles command line arguments and gets things started.

    Parameters
    ----------
    argv : list of str
        List of arguments, as if specified on the command-line.
        If None, ``sys.argv[1:]`` is used instead.
    """

    # Get command line arguments
    parser = argparse.ArgumentParser(
        description="Loads a trained model and outputs predictions based \
                     on input feature files.",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
        conflict_handler='resolve')
    parser.add_argument('model_file',
                        help='Model file to load and use for generating '
                             'predictions.')
    parser.add_argument('input_files',
                        help='A space-separated list of CSV, TSV, or '
                             'jsonlines files (with or without the label '
                             'column), with the appropriate suffix.',
                        nargs='+')
    parser.add_argument('-i', '--id_col',
                        help='Name of the column which contains the instance '
                             'IDs in ARFF, CSV, or TSV files.',
                        default='id')
    parser.add_argument('-l', '--infer_labels',
                        help="If the model being used is "
                             "doing probabilistic classification, "
                             "output the class label with the "
                             "highest probability instead of all "
                             "the probabilities.",
                             action='store_true',
                             default=False)
    parser.add_argument('-t', '--threshold',
                        help="If the model we're using is "
                             "doing probabilistic binary "
                             "classification, output the positive "
                             "class label if its probability"
                             "meets/exceeds this threshold"
                             "and output the negative class "
                             "label otherwise.", type=float)
    parser.add_argument('-q', '--quiet',
                        help='Suppress printing of "Loading..." messages.',
                        action='store_true')
    parser.add_argument('--output_file', '-o',
                        help="Path to output tsv file. If not specified, "
                             "predictions will be printed to stdout.")
    parser.add_argument('--version', action='version',
                        version='%(prog)s {0}'.format(__version__))

    args = parser.parse_args(argv)

    # Make warnings from built-in warnings module get formatted more nicely
    logging.captureWarnings(True)
    logging.basicConfig(format=('%(asctime)s - %(name)s - %(levelname)s - ' +
                                '%(message)s'))
    logger = logging.getLogger(__name__)

    # load the model from disk
    learner = Learner.from_file(args.model_file)

    # is the model a regressor or a classifier?
    estimator_type = learner._model.estimator_type

    # if we want to infer the most likely label from probabilities
    # or threshold the probabilities, make sure that the learner
    # is probabilistic first
    if ((args.infer_labels or args.threshold is not None) and
            not hasattr(learner._model, 'predict_proba')):
        logger.error('Cannot infer labels or threshold since '
                     'given {} learner is non-probabilistic'
                     '.'.format(learner._model_type.__name__))
        raise ValueError('Probabilities not supported')

    # iterate over all the specified input files
    for i, input_file in enumerate(args.input_files):

        # make sure each file extension is one we can process
        input_extension = os.path.splitext(input_file)[1].lower()
        if input_extension not in EXT_TO_READER:
            logger.error(('Input file must be in either .arff, .csv, '
                          '.jsonlines, .libsvm, .megam, .ndj, or .tsv format. '
                          ' Skipping file {}').format(input_file))
            continue
        else:
            # read in the file into a featureset and get its predictions
            reader = EXT_TO_READER[input_extension](input_file,
                                                    quiet=args.quiet,
                                                    label_col=args.label_col,
                                                    id_col=args.id_col)
            feature_set = reader.read()

            # note that the predictions may either be the probabiltiies
            # or the most likely labels; if the model is a regressor then
            # `class_labels` will be ignored entirely
            predictions = learner.predict(feature_set, class_labels=True)

            # get the appropriate header depending on the what we will
            # be outputting; if we are using a regressor or a non-probabilistic
            # learner, or thresholding probabilities, or inferring most likely
            # labels, we are outputting only two columns - the ID and the label,
            # otherwise we are outputting N + 1 columns where N = number of classes
            if (estimator_type == 'regressor' or
                    not learner.probability or
                    args.infer_labels or
                    args.threshold is not None):
                header = ["id", "prediction"]
            else:
                header = ["id"] + [""]



            if learner.probability:

            if args.output_file is not None:
                with open(args.output_file, 'a') as outputfh:
                    if i == 0:  # Only write header once per set of input files
                        print("\t".join(header), file=outputfh)
                    if args.all_probabilities:
                        for j, probabilities in enumerate(preds):
                            id_ = feature_set.ids[j]
                            probs_str = "\t".join([str(p) for p in probabilities])
                            print("{}\t{}".format(id_, probs_str), file=outputfh)
                    else:
                        for j, pred in enumerate(preds):
                            id_ = feature_set.ids[j]
                            print("{}\t{}".format(id_, pred), file=outputfh)
            else:
                if i == 0:  # Only write header once per set of input files
                    print("\t".join(header))
                if args.all_probabilities:
                    for j, probabilities in enumerate(preds):
                        id_ = feature_set.ids[j]
                        probs_str = "\t".join([str(p) for p in probabilities])
                        print("{}\t{}".format(id_, probs_str))
                else:
                    for j, pred in enumerate(preds):
                        id_ = feature_set.ids[j]
                        print("{}\t{}".format(id_, pred))


if __name__ == '__main__':
    main()
